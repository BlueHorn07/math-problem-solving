---
title: "Point and Interval Estimation"
layout: post
use_math: true
tags: ["Statistics"]
---

### ì„œë¡ 
2021-1í•™ê¸°, ëŒ€í•™ì—ì„œ 'í™•ë¥ ê³¼ í†µê³„' ìˆ˜ì—…ì„ ë“£ê³  ê³µë¶€í•œ ë°”ë¥¼ ì •ë¦¬í•œ ê¸€ì…ë‹ˆë‹¤. ì§€ì ì€ ì–¸ì œë‚˜ í™˜ì˜ì…ë‹ˆë‹¤ :)

<br><span class="statement-title">TOC.</span><br>

- Introduction to Estimation
- Point Estimation
- Interval Estimation

<hr/>

<div class="statement" markdown="1">

"\<**Statistics**\> is the area of science which can make inferences from data set."

</div>

<div class="statement" markdown="1">

"\<**Statistical inference**\> means making generalization about the <u>population properties</u> <u>based on a random sample</u>."

</div>

Supp. someone gave you some data set $\\{ x_1, \dots, x_n \\}$ and it is known that this data set is taken from a normal random sample $X_i \sim N(\mu, 1)$.

Q. You are asked to estimate $\mu$. What ca be a good estimate of $\mu$ from the sample?

A. $\bar{X}$, sample mean

why? by LLN, $\bar{X} \rightarrow \mu$ as $n \rightarrow \infty$.

ì´ë•Œ, $\bar{X}$ì˜ ê²½ìš°, true parameter $\mu$ì— ëŒ€í•´ $\mathbb{R}$ì— ì†í•˜ëŠ” ì–´ë–¤ í•˜ë‚˜ì˜ ê°’ì„ ì£¼ê²Œ ëœë‹¤. ì´ëŸ° í˜•íƒœì˜ estimationì„ \<**point estimation**\>ì´ë¼ê³  í•œë‹¤.

We may provide some interval which $\mu$ sits with some "high confidence".

ex) $P\left( \mu \in (a, b) \right) \approx 0.99 \quad \text{or} \quad 0.95$.

ì´ëŸ° í˜•íƒœì˜ estimationì„ \<**interval estimation**\>ì´ë¼ê³  í•œë‹¤.

ğŸ’¥ Note: For true distribution $N(\mu, \sigma^2)$, $\mu$, $\sigma$ are <span class="half_HL">unknown, but not random</span>!!

<hr/>

### Point Estimation

Let $X_1, \dots, X_n$ be a random sample and $X_i \sim f(x; \theta)$ for some pdf(or pmf), and let $x_1, \dots, x_n$ be sample points.

A \<point estimation\> of some population parameter $\theta$ is <span class="half_HL">a single value $\hat{\theta}$ of statistic $\hat{\Theta}$</span>.

ğŸ’¥ ì´ë•Œ, $\hat{\Theta}$ëŠ” estimatorì´ë©°, Random Variableì´ë‹¤.

<br>

<span class="statement-title">Example.</span><br>

Let $X_1, X_2, \dots, X_n$ be a random sample taken from $N(\mu, \sigma^2)$.

Q1\. What ca be a point estimator of $\mu$?

A1. sample mean, $\bar{X} = \dfrac{X_1 + \cdots + X_n}{n}$.

<br/>

Q2. How about a point estimator of $\sigma^2$?

A2. sample variance, $\displaystyle S^2 = \dfrac{1}{n-1} \sum^n_i (X_i - \bar{X})^2$ where $E[S^2] = \sigma^2$

or $\displaystyle \hat{S}^2 = \dfrac{1}{n} \sum^n_i (X_i - \bar{X})^2$ where $E[\hat{S}^2] = \dfrac{n-1}{n} \sigma^2$.

Q3. ë‘ estimator ì¤‘ ì–´ë–¤ ê²ƒì´ ë” ì¢‹ì€ê°€?

A3. ë‘ estimatorì˜ \<bias\>ë¥¼ ë¹„êµí•´ë³´ì!

<br/>

<span class="statement-title">Definition.</span> unbaised estimator ğŸ”¥<br>

A statistic $\hat{\Theta}$ is called an \<**unbiased estimator**\> if

$$
E[\hat{\Theta}] = \theta \quad \text{for all} \quad \theta
$$

$E[\hat{\Theta} - \theta]$ is the bias of $\hat{\Theta}$ related to $\theta$.

ğŸ’¥ $E[\hat{\Theta} - \theta] = 0$, unbiased!

<br/>

<span class="statement-title">Example.</span><br>




